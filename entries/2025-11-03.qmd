---
title: "2025-11-03"
format:
  html: default
  pdf: default
params:
  course: "mc451"
  word_min: 250
  word_max: 300
  p1: 'Have you ever worked with a spreadsheet, dataset, or even a shared document that felt chaotic or disorganized? Describe the experience. What kinds of "messiness" did you encounter? Looking back, which data wrangling principles from this chapter would have helped clean it up?'
  p2: 'Imagine you''re analyzing survey data and discover that some responses are missing or strangely formatted. You realize you could remove them, impute values, or rewrite categories to make things "fit." What would guide your decision-making in that situation? How does data cleaning impact the honesty and transparency of research?'
  p3: 'The chapter argues that wrangling is not just technical work—it’s interpretive. Think about a time you had to make a judgment call while organizing information (e.g., editing a document, categorizing files, formatting content). How might similar interpretive choices show up in data wrangling? How does this shape the final story your data tells?'
---

## Choose **one** prompt to answer

> **Prompt C:** `r params$p3`

---

## Response

<!-- RESPONSE-START -->
Each week, for every class, I am organizing and formatting my notes, making interpretative decisions. Deciding which information is important enough to be bolded, where I should section off certain topics and just general rearranging so I can easily read or scan my notes and find things without strain. I’m constantly making judgment calls about what matters most, what connects to what and how to represent that visually. I decide when something deserves its own section or when a topic should stay within the same category.

I suppose, in a way, that is similar to data wrangling. When someone is structuring data, they aren’t really just doing technical work, they’re making interpretive choices about what is relevant and how to group things. I might choose to highlight a concept that seems most important for understanding a class lecture, and a person wrangling data might decide which variables are worth keeping in their dataset. Both shape a final project, just in different ways.<!-- RESPONSE-END -->

---

## Word Count & Range Check

```{r}
#| echo: false
#| message: false
#| warning: false
get_response_text <- function() {
  f <- knitr::current_input()
  if (is.null(f) || !file.exists(f)) return("")
  x <- readLines(f, warn = FALSE)
  # Find the lines that EXACTLY match the start/end markers
  s <- grep("^<!-- RESPONSE-START -->$", x)
  e <- grep("^<!-- RESPONSE-END -->$", x)
  if (length(s) != 1 || length(e) != 1 || e <= s) return("")
  paste(x[(s + 1L):(e - 1L)], collapse = "\n")
}
count_words <- function(txt) {
  # Remove code blocks and inline code before counting
  txt <- gsub("```[\\s\\S]*?```", " ", txt, perl = TRUE)
  txt <- gsub("`[^`]*`", " ", txt, perl = TRUE)
  # Keep letters, numbers, spaces, hyphens, and apostrophes
  txt <- gsub("[^\\p{L}\\p{N}\\s'-]", " ", txt, perl = TRUE)
  # Split by whitespace and count non-empty words
  words <- unlist(strsplit(txt, "\\s+", perl = TRUE))
  words <- words[nzchar(words)]
  length(words)
}
txt <- get_response_text()
n <- count_words(txt)
minw <- as.integer(params$word_min)
maxw <- as.integer(params$word_max)
in_range <- n >= minw && n <= maxw
cat(sprintf("**Word count:** %d  \n", n))
cat(sprintf("**Required range (%s):** %d–%d words  \n",
            toupper(params$course), minw, maxw))
cat(if (in_range) "**Status:** ✅ In range\n" else "**Status:** ❌ Out of range\n")
```
